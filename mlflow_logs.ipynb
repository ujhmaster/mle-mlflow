{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import psycopg2 as psycopg\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = {\"sslmode\": \"require\", \"target_session_attrs\": \"read-write\"}\n",
    "postgres_credentials = {\n",
    "    \"host\": os.environ.get(\"DB_DESTINATION_HOST\"), \n",
    "    \"port\": os.environ.get(\"DB_DESTINATION_PORT\"),\n",
    "    \"dbname\": os.environ.get(\"DB_DESTINATION_NAME\"),\n",
    "    \"user\": os.environ.get(\"DB_DESTINATION_USER\"),\n",
    "    \"password\": os.environ.get(\"DB_DESTINATION_PASSWORD\"),\n",
    "}\n",
    "assert all([var_value != \"\" for var_value in list(postgres_credentials.values())])\n",
    "\n",
    "connection.update(postgres_credentials)\n",
    "\n",
    "# определим название таблицы, в которой хранятся наши данные.\n",
    "TABLE_NAME = \"users_churn\"\n",
    "\n",
    "# эта конструкция создаёт контекстное управление для соединения с базой данных \n",
    "# оператор with гарантирует, что соединение будет корректно закрыто после выполнения всех операций \n",
    "# закрыто оно будет даже в случае ошибки, чтобы не допустить \"утечку памяти\"\n",
    "with psycopg.connect(**connection) as conn:\n",
    "\n",
    "# создаёт объект курсора для выполнения запросов к базе данных\n",
    "# с помощью метода execute() выполняется SQL-запрос для выборки данных из таблицы TABLE_NAME\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(f\"SELECT * FROM {TABLE_NAME}\")\n",
    "                \n",
    "                # извлекаем все строки, полученные в результате выполнения запроса\n",
    "        data = cur.fetchall()\n",
    "\n",
    "                # получает список имён столбцов из объекта курсора\n",
    "        columns = [col[0] for col in cur.description]\n",
    "\n",
    "# создаёт объект DataFrame из полученных данных и имён столбцов. \n",
    "# это позволяет удобно работать с данными в Python, используя библиотеку Pandas.\n",
    "df = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"columns.txt\", \"w\", encoding=\"utf-8\") as fio:\n",
    "    fio.write(','.join(columns[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_columns = [\n",
    "    \"type\", \"paperless_billing\", \"internet_service\", \"online_security\", \"online_backup\", \"device_protection\",\n",
    "    \"tech_support\", \"streaming_tv\", \"streaming_movies\", \"gender\", \"senior_citizen\", \"partner\", \"dependents\",\n",
    "    \"multiple_lines\", \"target\"\n",
    "]\n",
    "\n",
    "stats = {}\n",
    "\n",
    "for col in counts_columns:\n",
    "\t\t# посчитайте уникальные значения для колонок, где немного уникальных значений (переменная counts_columns)\n",
    "    column_stat = df[col].value_counts()\n",
    "    column_stat = {f\"{col}_{key}\": value for key, value in column_stat.items()}\n",
    "\n",
    "\t\t# обновите словарь stats\n",
    "    stats.update(column_stat)\n",
    "\n",
    "\n",
    "stats[\"data_length\"] = df.shape[0]\n",
    "stats[\"monthly_charges_min\"] = df[\"monthly_charges\"].min()\n",
    "stats[\"monthly_charges_max\"] = df[\"monthly_charges\"].max()\n",
    "stats[\"monthly_charges_mean\"] = df[\"monthly_charges\"].mean() # посчитайте среднее значение в колонке\n",
    "stats[\"monthly_charges_median\"] = df[\"monthly_charges\"].median() # посчитайте медианное значение в колонке\n",
    "stats[\"total_charges_min\"] = df[\"total_charges\"].min() # посчитайте минимальное значение в колонке\n",
    "stats[\"total_charges_max\"] = df[\"total_charges\"].max() # посчитайте максимальное значение в колонке\n",
    "stats[\"total_charges_mean\"] = df[\"total_charges\"].mean() # посчитайте среднее значение в колонке\n",
    "stats[\"total_charges_median\"] = df[\"total_charges\"].median() # посчитайте медианное значение в колонке\n",
    "stats[\"unique_customers_number\"] = df[\"customer_id\"].nunique() # посчитайте кол-во уникальных id\n",
    "stats[\"end_date_nan\"] = df[\"end_date\"].isnull().sum() # посчитайте кол-во пустых строк в колонке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"users_churn.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_SERVER_HOST = \"127.0.0.1\"\n",
    "TRACKING_SERVER_PORT = 5000\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:{TRACKING_SERVER_PORT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY_ID=os.environ.get(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY=os.environ.get(\"AWS_SECRET_ACCESS_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "S3UploadFailedError",
     "evalue": "Failed to upload columns.txt to s3-student-mle-20240729-393dbfd5ab/10/c6acda24bbf148e8b06b0f1c7fbb6f9f/artifacts/dataframe/columns.txt: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/boto3/s3/transfer.py:371\u001b[0m, in \u001b[0;36mS3Transfer.upload_file\u001b[0;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 371\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# client error.\u001b[39;00m\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/s3transfer/futures.py:103\u001b[0m, in \u001b[0;36mTransferFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# Usually the result() method blocks until the transfer is done,\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# however if a KeyboardInterrupt is raised we want want to exit\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# out of this and propagate the exception.\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/s3transfer/futures.py:266\u001b[0m, in \u001b[0;36mTransferCoordinator.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/s3transfer/tasks.py:139\u001b[0m, in \u001b[0;36mTask.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_coordinator\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/s3transfer/tasks.py:162\u001b[0m, in \u001b[0;36mTask._execute_main\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuting task \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with kwargs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs_to_display\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 162\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m# If the task is the final task, then set the TransferFuture's\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# value to the return value from main().\u001b[39;00m\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/s3transfer/upload.py:764\u001b[0m, in \u001b[0;36mPutObjectTask._main\u001b[0;34m(self, client, fileobj, bucket, key, extra_args)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fileobj \u001b[38;5;28;01mas\u001b[39;00m body:\n\u001b[0;32m--> 764\u001b[0m     \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/botocore/client.py:1017\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mS3UploadFailedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_metrics(stats)\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# логируем файлы как артефакты эксперимента — 'columns.txt' и 'users_churn.csv'\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDIR_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_artifact(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musers_churn.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,artifact_path\u001b[38;5;241m=\u001b[39mDIR_PATH)\n\u001b[1;32m     27\u001b[0m experiment \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mget_experiment_by_name(EXPERIMENT_NAME)\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/mlflow/tracking/fluent.py:874\u001b[0m, in \u001b[0;36mlog_artifact\u001b[0;34m(local_path, artifact_path)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    852\u001b[0m \u001b[38;5;124;03mLog a local file or directory as an artifact of the currently active run. If no run is\u001b[39;00m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;124;03mactive, this method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;124;03m        mlflow.log_artifact(\"features.txt\")\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    873\u001b[0m run_id \u001b[38;5;241m=\u001b[39m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m--> 874\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/mlflow/tracking/client.py:1092\u001b[0m, in \u001b[0;36mMlflowClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_artifact\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, local_path, artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;124;03m    Write a local file or directory to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;124;03m        is_dir: False\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1092\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:454\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifact\u001b[0;34m(self, run_id, local_path, artifact_path)\u001b[0m\n\u001b[1;32m    452\u001b[0m     artifact_repo\u001b[38;5;241m.\u001b[39mlog_artifacts(local_path, path_name)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     \u001b[43martifact_repo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/mlflow/store/artifact/s3_artifact_repo.py:165\u001b[0m, in \u001b[0;36mS3ArtifactRepository.log_artifact\u001b[0;34m(self, local_file, artifact_path)\u001b[0m\n\u001b[1;32m    163\u001b[0m     dest_path \u001b[38;5;241m=\u001b[39m posixpath\u001b[38;5;241m.\u001b[39mjoin(dest_path, artifact_path)\n\u001b[1;32m    164\u001b[0m dest_path \u001b[38;5;241m=\u001b[39m posixpath\u001b[38;5;241m.\u001b[39mjoin(dest_path, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(local_file))\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43ms3_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_s3_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdest_path\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/mlflow/store/artifact/s3_artifact_repo.py:158\u001b[0m, in \u001b[0;36mS3ArtifactRepository._upload_file\u001b[0;34m(self, s3_client, local_file, bucket, key)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m environ_extra_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     extra_args\u001b[38;5;241m.\u001b[39mupdate(environ_extra_args)\n\u001b[0;32m--> 158\u001b[0m \u001b[43ms3_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mExtraArgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/boto3/s3/inject.py:145\u001b[0m, in \u001b[0;36mupload_file\u001b[0;34m(self, Filename, Bucket, Key, ExtraArgs, Callback, Config)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Upload a file to an S3 object.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03mUsage::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    transfer.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m S3Transfer(\u001b[38;5;28mself\u001b[39m, Config) \u001b[38;5;28;01mas\u001b[39;00m transfer:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransfer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mExtraArgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mle_projects/mle-mlflow/.venv_mlflow/lib/python3.10/site-packages/boto3/s3/transfer.py:377\u001b[0m, in \u001b[0;36mS3Transfer.upload_file\u001b[0;34m(self, filename, bucket, key, callback, extra_args)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# If a client error was raised, add the backwards compatibility layer\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# that raises a S3UploadFailedError. These specific errors were only\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# ever thrown for upload_parts but now can be thrown for any related\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# client error.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m S3UploadFailedError(\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to upload \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    379\u001b[0m             filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([bucket, key]), e\n\u001b[1;32m    380\u001b[0m         )\n\u001b[1;32m    381\u001b[0m     )\n",
      "\u001b[0;31mS3UploadFailedError\u001b[0m: Failed to upload columns.txt to s3-student-mle-20240729-393dbfd5ab/10/c6acda24bbf148e8b06b0f1c7fbb6f9f/artifacts/dataframe/columns.txt: An error occurred (InvalidAccessKeyId) when calling the PutObject operation: The AWS Access Key Id you provided does not exist in our records."
     ]
    }
   ],
   "source": [
    "# задаём название эксперимента и имя запуска для логирования в MLflow\n",
    "\n",
    "EXPERIMENT_NAME = \"churn_fio_3\"\n",
    "RUN_NAME = \"data_check\"\n",
    "DIR_PATH = 'dataframe'\n",
    "\n",
    "# создаём новый эксперимент в MLflow с указанным названием \n",
    "# если эксперимент с таким именем уже существует, \n",
    "# MLflow возвращает идентификатор существующего эксперимента\n",
    "#experiment_id = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "experiment_id = mlflow.create_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "with mlflow.start_run(run_name=RUN_NAME, experiment_id=experiment_id) as run:\n",
    "    # получаем уникальный идентификатор запуска эксперимента\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # логируем метрики эксперимента\n",
    "    # предполагается, что переменная stats содержит словарь с метриками,\n",
    "    # где ключи — это названия метрик, а значения — числовые значения метрик\n",
    "    mlflow.log_metrics(stats)\n",
    "    \n",
    "    # логируем файлы как артефакты эксперимента — 'columns.txt' и 'users_churn.csv'\n",
    "    mlflow.log_artifact(\"columns.txt\",artifact_path=DIR_PATH)\n",
    "    mlflow.log_artifact(\"users_churn.csv\",artifact_path=DIR_PATH)\n",
    "\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "# получаем данные о запуске эксперимента по его уникальному идентификатору\n",
    "run = mlflow.get_run(run_id)\n",
    "\n",
    "\n",
    "# проверяем, что статус запуска эксперимента изменён на 'FINISHED'\n",
    "# это утверждение (assert) можно использовать для автоматической проверки того, \n",
    "# что эксперимент был завершён успешно\n",
    "assert 'FINISHED' == run.info.status\n",
    "\n",
    "# удаляем файлы 'columns.txt' и 'users_churn.csv' из файловой системы,\n",
    "# чтобы очистить рабочую среду после логирования артефактов\n",
    "os.remove(\"columns.txt\")\n",
    "os.remove(\"users_churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_results/cv_res.json\n",
      "data/initial_data.csv\n",
      "models/fitted_model.pkl\n",
      "part2_dvc/cv_results/cv_res.json\n",
      "part2_dvc/data/initial_data.csv\n",
      "part2_dvc/models/fitted_model.pkl\n"
     ]
    }
   ],
   "source": [
    "def get_session_student():\n",
    "    session = boto3.session.Session()\n",
    "\n",
    "    return session.client(\n",
    "        service_name='s3',\n",
    "        endpoint_url='https://storage.yandexcloud.net',\n",
    "        aws_access_key_id=os.environ.get(\"AWS_ACCESS_KEY_ID\"),\n",
    "        aws_secret_access_key=os.environ.get(\"AWS_SECRET_ACCESS_KEY\")\n",
    "    )\n",
    "\n",
    "s3 = get_session_student()\n",
    "bucket_name = os.environ.get('S3_BUCKET_NAME')\n",
    "if s3.list_objects(Bucket=bucket_name)['Contents']:\n",
    "    for key in s3.list_objects(Bucket=bucket_name)['Contents']:\n",
    "        print(key['Key'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
